{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79600238",
   "metadata": {},
   "source": [
    "# APLICACIÓN\n",
    "\n",
    "En este archivo se encuentra la aplicación con los dos modelos desplegados:\n",
    "- Transfer-learning Model: Es la arquitectura que tiene la transferencia de capas desde un modelo pre-entrenado (lo pre-entrenamos nosotros mismos -archivo subBigGAN.ipynb-) con los datos de CIFAR10.\n",
    "\n",
    "\n",
    "- Scratch Model: Este modelo fue entrenado por la arquitectura de cGAN desde 0 con el total de imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "17ca9c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow/Keras: 2.11.0\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import os\n",
    "from tensorflow import train\n",
    "#from helpers import load_data # la función fue creada por nostros, para más info ver el notebook de data.ipynb\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras # for building Neural Networks\n",
    "print('Tensorflow/Keras: %s' % keras.__version__) # print version\n",
    "from tensorflow.keras.models import Model, load_model # for assembling a Neural Network model\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Reshape, Concatenate, Flatten, Dropout # for adding layers\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, MaxPool2D, ReLU, LeakyReLU # for adding layers\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import plot_model # for plotting model diagram\n",
    "from tensorflow.keras.optimizers import Adam # for model optimization \n",
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06038aeb",
   "metadata": {},
   "source": [
    "## LOGIC\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "186ae0bc",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "def scratch_generator(latent_dim, in_shape=(4,4,1), n_cats=3):\n",
    "    # TODO: cambiar inshape a 8x8x1\n",
    "    # Label Inputs\n",
    "    in_label = Input(shape=(1,), name='Generator-Label-Input-Layer') # Input Layer\n",
    "    lbls = Embedding(input_dim = n_cats, output_dim = 50,\n",
    "                     name='Generator-Label-Embedding-Layer')(in_label) # Embed label to vector\n",
    "    \n",
    "    # Generator Inputs (latent vector)\n",
    "    in_latent = Input(shape=latent_dim, name='Generator-Latent-Input-Layer')\n",
    "    # Scale up to image dimensions\n",
    "    n_nodes = in_shape[0] * in_shape[1] \n",
    "    lbls = Dense(n_nodes, name='Generator-Label-Dense-Layer')(lbls)\n",
    "    lbls = Reshape((in_shape[0], in_shape[1], 1), name='Generator-Label-Reshape-Layer')(lbls) # New shape\n",
    "\n",
    "    # Generator Inputs (latent vector)\n",
    "    in_latent = Input(shape=latent_dim, name='Generator-Latent-Input-Layer')\n",
    "    \n",
    "    # Image Foundation \n",
    "    n_nodes = in_shape[0] * in_shape[1] * 256 \n",
    "    g = Dense(n_nodes, name='Generator-Foundation-Layer')(in_latent)\n",
    "    g = ReLU(name='Generator-Foundation-Layer-Activation-1')(g)\n",
    "    g = Reshape((in_shape[0], in_shape[1], 256), name='Generator-Foundation-Layer-Reshape-1')(g)\n",
    "    \n",
    "    # Combine both inputs so it has two channels\n",
    "    concat = Concatenate(name='Generator-Combine-Layer')([g, lbls])\n",
    "\n",
    "    # Hidden Layer 1\n",
    "    g = Conv2DTranspose(filters=128, kernel_size=(4,4), strides=(2,2), padding='same', name='Generator-Hidden-Layer-1')(concat)\n",
    "    g = LeakyReLU(alpha=0.2, name='Generator-Hidden-Layer-Activation-1')(g)\n",
    "    \n",
    "    # Hidden Layer 2\n",
    "    g = Conv2DTranspose(filters=128, kernel_size=(4,4), strides=(2,2), padding='same', name='Generator-Hidden-Layer-2')(g)\n",
    "    g = LeakyReLU(alpha=0.2, name='Generator-Hidden-Layer-Activation-2')(g)\n",
    "    \n",
    "    # Hidden Layer 3\n",
    "    g = Conv2DTranspose(filters=128, kernel_size=(4,4), strides=(2,2), padding='same', name='Generator-Hidden-Layer-3')(g)\n",
    "    g = LeakyReLU(alpha=0.2, name='Generator-Hidden-Layer-Activation-3')(g)\n",
    "    \n",
    "    # Hidden Layer 4\n",
    "    # g = Conv2DTranspose(filters=128, kernel_size=(4,4), strides=(2,2), padding='same', name='Generator-Hidden-Layer-4')(g)\n",
    "    # g = ReLU(name='Generator-Hidden-Layer-Activation-4')(g)\n",
    "    \n",
    "    # Output Layer (Note, we use only one filter because we have a greysclae image. Color image would have three\n",
    "    output_layer = Conv2D(filters=3, kernel_size=(7,7), activation='tanh', padding='same', name='Generator-Output-Layer')(g)\n",
    "    # TODO: cambiar filters a 3\n",
    "    # Define model\n",
    "    model = Model([in_latent, in_label], output_layer, name='Generator')\n",
    "    return model\n",
    "\n",
    "def transfer_generator(latent_dim, in_shape=(4,4,1), n_cats=3):\n",
    "    # TODO: cambiar inshape a 8x8x1\n",
    "    # Label Inputs\n",
    "    in_label = Input(shape=(1,), name='Generator-Label-Input-Layer') # Input Layer\n",
    "    lbls = Embedding(input_dim = n_cats, output_dim = 50,\n",
    "                     name='Generator-Label-Embedding-Layer')(in_label) # Embed label to vector\n",
    "    \n",
    "    # Generator Inputs (latent vector)\n",
    "    in_latent = Input(shape=latent_dim, name='Generator-Latent-Input-Layer')\n",
    "    # Scale up to image dimensions\n",
    "    n_nodes = in_shape[0] * in_shape[1] \n",
    "    lbls = Dense(n_nodes, name='Generator-Label-Dense-Layer')(lbls)\n",
    "    lbls = Reshape((in_shape[0], in_shape[1], 1), name='Generator-Label-Reshape-Layer')(lbls) # New shape\n",
    "\n",
    "    # Generator Inputs (latent vector)\n",
    "    in_latent = Input(shape=latent_dim, name='Generator-Latent-Input-Layer')\n",
    "    \n",
    "    # Image Foundation \n",
    "    n_nodes = in_shape[0] * in_shape[1] * 256 \n",
    "    g = Dense(n_nodes, name='Generator-Foundation-Layer')(in_latent)\n",
    "    g = ReLU(name='Generator-Foundation-Layer-Activation-1')(g)\n",
    "    g = Reshape((in_shape[0], in_shape[1], 256), name='Generator-Foundation-Layer-Reshape-1')(g)\n",
    "    \n",
    "    # Combine both inputs so it has two channels\n",
    "    concat = Concatenate(name='Generator-Combine-Layer')([g, lbls])\n",
    "\n",
    "    # Hidden Layer 1\n",
    "    g = Conv2DTranspose(filters=128, kernel_size=(4,4), strides=(2,2), padding='same', name='Generator-Hidden-Layer-1', trainable=False)(concat)\n",
    "    g = LeakyReLU(alpha=0.2, name='Generator-Hidden-Layer-Activation-1', trainable=False)(g)\n",
    "    \n",
    "    # Hidden Layer 2\n",
    "    g = Conv2DTranspose(filters=128, kernel_size=(4,4), strides=(2,2), padding='same', name='Generator-Hidden-Layer-2', trainable=False)(g)\n",
    "    g = LeakyReLU(alpha=0.2, name='Generator-Hidden-Layer-Activation-2', trainable=False)(g)\n",
    "    \n",
    "    # Hidden Layer 3\n",
    "    g = Conv2DTranspose(filters=128, kernel_size=(4,4), strides=(2,2), padding='same', name='Generator-Hidden-Layer-3', trainable=False)(g)\n",
    "    g = LeakyReLU(alpha=0.2, name='Generator-Hidden-Layer-Activation-3', trainable=False)(g)\n",
    "    \n",
    "    # Hidden Layer 4\n",
    "    # g = Conv2DTranspose(filters=128, kernel_size=(4,4), strides=(2,2), padding='same', name='Generator-Hidden-Layer-4')(g)\n",
    "    # g = ReLU(name='Generator-Hidden-Layer-Activation-4')(g)\n",
    "    g = Conv2DTranspose(filters=128, kernel_size=(4,4), padding='same', name='Generator-Hidden-Layer-4')(g)\n",
    "    g = LeakyReLU(alpha=0.2, name='Generator-Hidden-Layer-Activation-4')(g)\n",
    "    \n",
    "    # Hidden Layer 5\n",
    "    g = Conv2DTranspose(filters=128, kernel_size=(4,4), padding='same', name='Generator-Hidden-Layer-5')(g)\n",
    "    g = LeakyReLU(alpha=0.2, name='Generator-Hidden-Layer-Activation-5')(g)\n",
    "    \n",
    "    # Output Layer (Note, we use only one filter because we have a greysclae image. Color image would have three\n",
    "    output_layer = Conv2D(filters=3, kernel_size=(7,7), activation='tanh', padding='same', name='Generator-Output-Layer')(g)\n",
    "    # TODO: cambiar filters a 3\n",
    "    # Define model\n",
    "    model = Model([in_latent, in_label], output_layer, name='Generator')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "950b1e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator:\n",
    "    def __init__(self, checkpoint_dir_scratch, checkpoint_dir_transfer):\n",
    "        #instantiate generators\n",
    "        self.scratch = scratch_generator(latent_dim=100)\n",
    "        self.transfer = transfer_generator(latent_dim=100)\n",
    "        # get latest checkpoint\n",
    "        latest_scratch = train.latest_checkpoint(checkpoint_dir_scratch)\n",
    "        latest_transfer = train.latest_checkpoint(checkpoint_dir_transfer)\n",
    "        # load weights\n",
    "        self.scratch.load_weights(latest_scratch)\n",
    "        self.transfer.load_weights(latest_transfer)\n",
    "        self.labels_map = {\"Abstract\": 0, \"Geometric\": 1, \"Islamic\": 2}\n",
    "    \n",
    "    def generate(self, label: str, type_: str):\n",
    "        label = self.labels_map[label]\n",
    "        latent_points, _ = self.__latent_vector(100, 1)\n",
    "        if type_ == \"scratch\":\n",
    "            img  = self.scratch.predict([latent_points, np.array([label])])\n",
    "        elif type_ == \"transfer\":\n",
    "            img  = self.transfer.predict([latent_points, np.array([label])])\n",
    "        img = (img+1)/2.0\n",
    "        return img[0]\n",
    "    \n",
    "    def __latent_vector(self, latent_dim, n, n_cats=3):\n",
    "        # Generate points in the latent space\n",
    "        latent_input = np.random.randn(latent_dim * n)\n",
    "\n",
    "        # Reshape into a batch of inputs for the network\n",
    "        latent_input = latent_input.reshape(n, latent_dim)\n",
    "\n",
    "        # Generate category labels \n",
    "        cat_labels = np.random.randint(0, n_cats, n)\n",
    "        return [latent_input, cat_labels] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c0424b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir_scratch = \"checkpoints/checkpoints_scratch32\"\n",
    "latest_scratch = train.latest_checkpoint(checkpoint_dir_scratch)\n",
    "checkpoint_dir_transfer = \"checkpoints/checkpoints_transfer32\"\n",
    "latest_transfer = train.latest_checkpoint(checkpoint_dir_transfer)\n",
    "\n",
    "GAN = Generator(checkpoint_dir_scratch, checkpoint_dir_transfer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b7ebb9",
   "metadata": {},
   "source": [
    "# APP DEPLOYMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7358cb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7877\n",
      "Running on public URL: https://6e8eb49350d8db91.gradio.app\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://6e8eb49350d8db91.gradio.app\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n"
     ]
    }
   ],
   "source": [
    "def generate(Type_Art, Model_type):\n",
    "    label = Type_Art.split(\" \")[0]\n",
    "    type_ = \"transfer\" if Model_type ==\"Transfer-learning Model\" else \"scratch\"\n",
    "    return GAN.generate(label, type_)\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=generate,\n",
    "    inputs=[gr.Radio([\"Abstract Art\", \"Geometric Art\", \"Islamic Art\"]), gr.Radio([\"Transfer-learning Model\", \"Scratch Model\"])],\n",
    "    outputs=gr.Image(shape=(32, 32)), allow_flagging=\"never\"\n",
    ")\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d0740a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:MLT]",
   "language": "python",
   "name": "conda-env-MLT-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
